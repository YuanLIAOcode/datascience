{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "$\\def\\*#1{\\mathbf{#1}}$\n",
    "$\\DeclareMathOperator*{\\argmax}{arg\\,max}$\n",
    "# Linear Algebra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Information $\\rightarrow$ Matrix\n",
    "\n",
    "* Each row is a **record** (instance, object, point,...).\n",
    "* Each column is a **feature** (attribute, dimension,...).\n",
    "\n",
    "$$\n",
    "D = \n",
    "\\left(\n",
    "\\begin{array}{c|cccc}\n",
    "        & X_1 & X_2 & \\cdots & X_d\\\\\n",
    "        \\hline\n",
    "  \\*x_1 & x_{1,1} & x_{1,2} & \\cdots & x_{1,d} \\\\\n",
    "  \\*x_2 & x_{2,1} & x_{2,2} & \\cdots & x_{2,d} \\\\\n",
    "  \\vdots & \\vdots  & \\vdots  & \\ddots & \\vdots  \\\\\n",
    "  \\*x_n & x_{n,1} & x_{n,2} & \\cdots & x_{n,d} \n",
    "\\end{array}\n",
    "\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Linear algebra\n",
    "\n",
    "* *The mathematics of matrices*, therefore of curcial importance in data science.\n",
    "* To understand many *machine learning algorithms* \n",
    "\n",
    "A $m \\times n$ matrix can be used to represent objects such as :\n",
    "\n",
    "* Data\n",
    "* Geometric point sets\n",
    "* Systems of equations\n",
    "* Graphs and networks (see adjacency or incidence matrices)\n",
    "* Rearrangement operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Operations on matrices are available in linear algebra libraries (such as numpy.linalg); are developed to take advantage of the CPU architecture (see, [intel MKL](https://software.intel.com/en-us/mkl)). The idea is therefore to formulate our problems usin linear algebra in order to take advantage of these libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Geometry and vectors\n",
    "\n",
    "Points can be represented by a unit vector plus their magnitude :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.array([[1, 12, 4, 13, 3, 10],\n",
    "              [10, 1, 40, 1, 30, 1],\n",
    "              [0, 6, 2, 6, 1, 5],\n",
    "              [0.5, 6, 2, 6.5, 1.5, 5]])\n",
    "\n",
    "norms = np.linalg.norm(X, axis=1)\n",
    "norms = norms[:, np.newaxis]\n",
    "\n",
    "print('Unit vectors :', X/norms, sep='\\n')\n",
    "\n",
    "print('Magnitudes :', norms, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance\n",
    "\n",
    "Let's compute the scalar product between each unit vector :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xn = X/norms\n",
    "np.dot(Xn, Xn.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Compute the distance between points by the angles between vectors.\n",
    "\n",
    "$$\n",
    "cos(\\theta) = \\frac{A \\cdot B}{||A||\\ ||B||}\n",
    "$$\n",
    "\n",
    "$$\n",
    "cos(0) = 1, cos(\\pi/2) = 0, cos(\\pi) = -1\n",
    "$$\n",
    "\n",
    "Observations :\n",
    "\n",
    "* In the case of unit vectors, the *dot product* is equal to the cosine function.\n",
    "* The cosine function is equal to the correlation of two mean-zero variables :\n",
    "\n",
    "$$\n",
    "\\begin{aligned} \n",
    "r &= \\frac{\\sum_{i=1}^n(x_i - \\bar{x})(y_i - \\bar{y})}{\\sqrt{\\sum_{i=1}^n(x_i - \\bar{x})^2} \\sqrt{\\sum_{i=1}^n(y_i - \\bar{y})^2}}\\\\\n",
    "&= \\frac{\\sum_{i=1}^nx_i y_i}{\\sqrt{\\sum_{i=1}^nx_i^2} \\sqrt{\\sum_{i=1}^ny_i^2}}\\\\\n",
    "&= \\frac{\\*x \\cdot \\*y}{||\\*x||\\ ||\\*y||}\\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "* The dot product measure how \"in sync\" the two vectors are.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Matrix Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Matrix addition, linear combinations and transpose on pictures\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib notebook\n",
    "\n",
    "img = mpimg.imread('../datasets/stinkbug.png')\n",
    "height = img.shape[0]\n",
    "img = img[:, :height, 0]\n",
    "\n",
    "fix, axs = plt.subplots(nrows=2, ncols=2)\n",
    "\n",
    "axs[0, 0].imshow(img)\n",
    "axs[0, 1].imshow(img.T)\n",
    "axs[1, 0].imshow(img + img.T)\n",
    "axs[1, 1].imshow(img + 0.5 * img[:,::-1])\n",
    "\n",
    "for ax in axs.flatten():\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Matrix Product\n",
    "\n",
    "The matrix product $C = AB$ is defined as follows : \n",
    "\n",
    "$$\n",
    "C_{ij} = \\sum_{i=1}^k A_{ik}\\cdot B_{kj},\n",
    "$$\n",
    "\n",
    "where the *inner dimensions* of $A$ and $B$ have to be the same, *i.e.* if $A$ is an $n \\times k$ matrix, then $B$ has to be a $k \\times m$ matrix. \n",
    "\n",
    "The product matrix $C$, each $n \\times m$ element $C_{ij}$ is equal to the dot product of the $i$-th row of A with the $j$-th column of B."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Matrix multiplication *does not commute* :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "A = np.matrix([[1, 1], [0, 1]])\n",
    "B = np.matrix([[1, 1], [1, 0]])\n",
    "print(A.dot(B))\n",
    "print(B.dot(A))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "And obviously for non square matrices :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "A = np.random.rand(3, 4)\n",
    "B = np.random.rand(4, 2)\n",
    "print(A.dot(B))\n",
    "# print(B.dot(A)) the inner dimentions are different"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Matrix multiplication is *associative* :\n",
    "\n",
    "$$\n",
    "(AB)C = A(BC)\n",
    "$$\n",
    "\n",
    "Let us compare the computation time of $(AB)(CD)$ and $(A(BC))D$ when $A \\in \\mathbb{R}^{1 \\times n}$, $B, C \\in \\mathbb{R}^{n \\times n}$, and $D \\in \\mathbb{R}^{n \\times 1}$. (see, http://www.scipy-lectures.org/advanced/optimizing/ for optimization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "n = 1000\n",
    "A = np.random.randn(n)\n",
    "B = np.random.randn(n, n)\n",
    "C = np.random.randn(n, n)\n",
    "D = np.random.randn(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%timeit -n 30 -r 1 np.dot(np.dot(A, B), np.dot(C,D))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%timeit -n 30 -r 1 np.dot(np.dot(A, np.dot(B, C)), D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "By taking advantage of well optimized linear algebra libraries, formulating problems as matrix products (when considering large arrays) leads to very big performance wins in practice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Applications of Matrix multiplication\n",
    "\n",
    "Consider an $n \\times d$ data matrix $A$ :\n",
    "\n",
    "* $A \\cdot A^T$ : is an $n \\times m$ matrix of dot products, which measure the \"in sync-ness\" among the points\n",
    "* $A^T \\cdot A$ : is an $d \\times d$ matrix of dot products, which measure the \"in sync-ness among the features\n",
    "\n",
    "These matrices are the so-called **covariance matrices** when rows and colums have mean zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=3)\n",
    "\n",
    "M = mpimg.imread('../datasets/lincoln_memorial.png')[:,:,0]\n",
    "\n",
    "axs[0].imshow(M)\n",
    "axs[0].set_title('$M$')\n",
    "\n",
    "A = M/np.sqrt(np.sum(M*M, axis=1))[:, np.newaxis]\n",
    "\n",
    "axs[1].imshow(np.dot(A, A.T))\n",
    "axs[1].set_title('$M \\cdot M^T$')\n",
    "\n",
    "A = A/np.sqrt(np.sum(M*M, axis=0))\n",
    "\n",
    "axs[2].imshow(np.dot(A.T, A))\n",
    "axs[2].set_title('$M^T \\cdot M$')\n",
    "\n",
    "for ax in axs:\n",
    "    ax.axis('off')\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* The $k$th power of the **adjacency matrix** $A^k$ of a graph gives the number of path of length $k$ between each pair of vertex $(i, j)$.\n",
    "* Permutations (rows or columns):\n",
    "\n",
    "$$\n",
    "P_{(2431)} = \n",
    "\\left[\n",
    "\\begin{array}{cccc}\n",
    "  0 & 0 & 0 & 1 \\\\\n",
    "  1 & 0 & 0 & 0 \\\\\n",
    "  0 & 0 & 1 & 1 \\\\\n",
    "  0 & 1 & 0 & 0\n",
    "\\end{array}\n",
    "\\right]\n",
    "$$\n",
    "\n",
    "* Rotating points in space :\n",
    "\n",
    "$$\n",
    "R_{\\theta} = \n",
    "\\left[\n",
    "\\begin{array}{cc}\n",
    "\\cos(\\theta) & -\\sin(\\theta)\\\\\n",
    "\\sin(\\theta) & \\cos(\\theta)\n",
    "\\end{array}\n",
    "\\right]\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=2, ncols=2)\n",
    "n = M.shape[0]\n",
    "P = np.identity(n)\n",
    "P = np.concatenate((P[n//2:,:], P[:n//2,:]))\n",
    "\n",
    "axs[0, 0].imshow(M)\n",
    "axs[0, 0].set_title('$M$')\n",
    "\n",
    "axs[0, 1].imshow(P)\n",
    "axs[0, 1].set_title('$P$')\n",
    "\n",
    "axs[1, 0].imshow(np.dot(P, M))\n",
    "axs[1, 0].set_title('$P \\cdot M$')\n",
    "\n",
    "axs[1, 1].imshow(np.dot(M, P))\n",
    "axs[1, 1].set_title('$M \\cdot P$')\n",
    "\n",
    "for ax in axs.flatten():\n",
    "    ax.axis('off')\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Identity Matrices and Inversion\n",
    "\n",
    "* $IA = AI = A$\n",
    "* $A \\cdot A^{-1} = I$ \n",
    "\n",
    "For example, when $A$ is a $2 \\times 2$ matrix :\n",
    "\n",
    "$$\n",
    "A^{-1} = \\left[\n",
    "\\begin{array}{cc}\n",
    "a & b\\\\\n",
    "c & d\n",
    "\\end{array}\n",
    "\\right]^{-1}\n",
    "= \\frac{1}{ad - bc} \\left[\n",
    "\\begin{array}{cc}\n",
    "d & -b\\\\\n",
    "-c & a\n",
    "\\end{array}\n",
    "\\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from numpy.linalg import inv\n",
    "a = np.array([[1., 2.], [3., 4.]])\n",
    "ainv = inv(a)\n",
    "ainv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "a = np.array([[3., 2.], [3., 2.]])\n",
    "ainv = inv(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[3., 2.], [6., 4.]])\n",
    "ainv = inv(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "* Matrices that are not inversible are called *singular* (otherwise, *non-singular*).\n",
    "* If the *determinant* is not zero, the the matrix is *non-singular*.\n",
    "* Only squared matrices are inversible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Matrix Rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Factoring Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Eigenvalues and Eigenvectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Eigenvalue Decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## References\n",
    "\n",
    "* **The Data Science Design Manual**, by Steven Skiena, 2017, Springer;\n",
    "* Python notebooks available at [http://data-manual.com/data](http://data-manual.com/data);\n",
    "* Lectures slides available at [http://www3.cs.stonybrook.edu/~skiena/data-manual/lectures/](http://www3.cs.stonybrook.edu/~skiena/data-manual/lectures/);\n",
    "* https://matplotlib.org/users/image_tutorial.html."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
