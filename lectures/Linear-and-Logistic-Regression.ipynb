{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear and Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression can be used to build models based on training data:\n",
    "\n",
    "* Prediction\n",
    "* Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stock Market"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "smarket = pandas.read_csv('../datasets/Smarket.csv', index_col=0, parse_dates=True)\n",
    "smarket.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where *Lag1* through *Lag5* stand for the percentage returns for the five previous days.\n",
    "\n",
    "**Prediction** : Will the index increase or decrease based on the past 5 days' percentage changes in the index ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advertising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "advertising = pandas.read_csv('../datasets/Advertising.csv', index_col=0)\n",
    "advertising.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a particular **product**, this dataset provides for 200 markets :\n",
    "* Advertising budgets for TV, radio, and newspaper (in thousands of dollars)\n",
    "* The sales (in thousands of units)\n",
    "\n",
    "We wish to understand association between advertising and sales to control advertising expenditure in each of the three media. \n",
    "\n",
    "**Input variables** ($X$) :\n",
    "* $X_1$ : TV budget\n",
    "* $X_2$ : Radio budget\n",
    "* $X_3$ : newspaper budget\n",
    "\n",
    "**Output variable** :\n",
    "* $Y$ : Sales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relationship between $Y$ and $X$ :\n",
    "\n",
    "$$\n",
    "Y = f(X) + \\epsilon\n",
    "$$\n",
    "\n",
    "where $f$ is an unkdown function and $\\epsilon$ a random error term independent of $X$ and which has mean zero (otherwise easy to compensate by modifying $f$). This error cannot be reduced to zero. For example, it may depend on unmeasured variables that are useful for predicting the value of $Y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "advertising.plot(kind='scatter', color='Blue', x='TV', y='sales')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ordinary Least Squares\n",
    "X = advertising['TV']\n",
    "Y = advertising['sales']\n",
    "regression = np.polyfit(X, Y, deg=1)\n",
    "\n",
    "advertising.plot(kind='scatter', color='Blue', x='TV', y='sales')\n",
    "\n",
    "plt.plot(X, regression[0]*X + regression[1], 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression\n",
    "\n",
    "Given a collection of n points, find the line which best approximates or fits the points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a random noise\n",
    "x1 = np.random.normal(size=200)\n",
    "x = np.linspace(x1.min()-1, x1.max()+1, 100)\n",
    "y = 3*(np.random.normal(0, 1, 100)+x)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x, y , color='red')\n",
    "\n",
    "#Find the regression line\n",
    "regression = np.polyfit(x, y, 1)\n",
    "print(regression)\n",
    "longerX = np.append(x, [5,-5])\n",
    "ax.plot(longerX, regression[0]*longerX + regression[1], color='black', linewidth='1.5')\n",
    "ax.set_xlim(-4, 4.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "f(x) = mx + p\n",
    "$$\n",
    "\n",
    "The residual error is defined:\n",
    "\n",
    "$$\n",
    "r_i = y_i - f(x_i)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = np.linspace(0, 10, 100)\n",
    "y = 2*x+3\n",
    "#distance the dashed line is into the circle\n",
    "s = 0.4\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, y)\n",
    "ax.plot([1, 1, 2, 3, 3, 4, 4, 5, 6, 7],[7, 3, 12, 5, 11, 15, 10, 15, 12, 19], 'yo', markersize=7)\n",
    "ax.plot([1, 1], [7-s, 5], 'b-', [1, 1], [3+s, 5], 'b-', \\\n",
    "[2, 2], [12-s, 7], 'b-', [3, 3], [5+s, 9], 'b-', \\\n",
    "[3, 3], [11-s, 9], 'b-', [4,4], [15-s, 11], 'b-', \\\n",
    "[4,4], [10+s, 11], 'b-', [5, 5], [15-s, 13], 'b-',\\\n",
    "[6, 6], [12+s+0.1, 15], 'b-', [7, 7], [19-s, 17], 'b-', linestyle='dashed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consider a set of $n$ points $x_i = (x_{i1}, x_{i2}, \\ldots, x_{im})$, where\n",
    "$(x_{i1}, x_{i2}, \\ldots, x_{i(m-1)})$ is the feature vector and $x_{im}$ is\n",
    "the **target variable**.\n",
    "\n",
    "We use the **least squares regression** to find the optimal fit :\n",
    "\n",
    "$$\n",
    "\\sum_{i=1}^n (y_i - f(x_i))^2, \\text{where}\\ f(x) = w_0 + \\sum_{j=1}^{m-1}w_jx_j\n",
    "$$\n",
    "\n",
    "The vector of residual values :\n",
    "\n",
    "$$\n",
    "(b - A \\cdot w),\n",
    "$$\n",
    "\n",
    "where b, A, and w are defined as follows:\n",
    "\n",
    "$$\n",
    "b = \\left[\n",
    "\\begin{array}{c}\n",
    "  x_{1m}\\\\\n",
    "  x_{2m}\\\\\n",
    "  \\vdots \\\\\n",
    "  x_{im}\\\\\n",
    "  \\vdots \\\\\n",
    "  x_{nm}\n",
    "\\end{array}\n",
    "\\right], A = \\left[\n",
    "\\begin{array}{ccccccc}\n",
    "  1 & x_{11} & x_{12} & \\ldots & x_{1j} & \\ldots & x_{1(m-1)} \\\\\n",
    "  1 & x_{21} & x_{22} & \\ldots & x_{2j} & \\ldots & x_{2(m-1)} \\\\\n",
    "  \\vdots & \\vdots & \\vdots & \\ddots & \\vdots & \\ddots & \\vdots \\\\\n",
    "  1 & x_{i1} & x_{i2} & \\ldots & x_{ij} & \\ldots & x_{i(m-1)} \\\\\n",
    "  \\vdots & \\vdots & \\vdots & \\ddots & \\vdots & \\ddots & \\vdots \\\\\n",
    "  1 & x_{n1} & x_{n2} & \\ldots & x_{nj} & \\ldots & x_{n(m-1)}\n",
    "\\end{array}\n",
    "\\right], w = \\left[\n",
    "\\begin{array}{c}\n",
    "  w_0\\\\\n",
    "  w_1\\\\\n",
    "  \\vdots \\\\\n",
    "  w_j \\\\\n",
    "  \\vdots \\\\\n",
    "  w_{(m-1)}\n",
    "\\end{array}\n",
    "\\right].\n",
    "$$\n",
    "\n",
    "The vector $w$ that leads to the best fitting line is given by :\n",
    "\n",
    "$$\n",
    "w = (A^T A)^{-1}A^T b\n",
    "$$\n",
    "\n",
    "The right-hand side of this equation comprises the following components:\n",
    "\n",
    "* $A^T A$ : the *covariance matrix* on the features of the data matrix\n",
    "* $A^T b$ : this dot product between features and the target values measure how correlated are each feature with the targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting Non-Linear Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlated Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression as a Parameter Fitting Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "* [An Introduction to Statistical Learning with Applications in R](http://www-bcf.usc.edu/~gareth/ISL/) by Gareth James, Daniela Witten, Trevor Hastie and Robert Tibshirani\n",
    "* **The Data Science Design Manual**, by Steven Skiena, 2017, Springer\n",
    "* Python notebooks available at [http://data-manual.com/data](http://data-manual.com/data)\n",
    "* Lectures slides available at [http://www3.cs.stonybrook.edu/~skiena/data-manual/lectures/](http://www3.cs.stonybrook.edu/~skiena/data-manual/lectures/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
