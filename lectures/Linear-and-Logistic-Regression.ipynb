{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear and Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "%matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression can be used to build models based on training data:\n",
    "\n",
    "* Prediction\n",
    "* Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stock Market"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "smarket = pandas.read_csv('../datasets/Smarket.csv', index_col=0, parse_dates=True)\n",
    "smarket.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where *Lag1* through *Lag5* stand for the percentage returns for the five previous days.\n",
    "\n",
    "**Prediction** : Will the index increase or decrease based on the past 5 days' percentage changes in the index ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advertising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "advertising = pandas.read_csv('../datasets/Advertising.csv', index_col=0)\n",
    "advertising.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a particular **product**, this dataset provides for 200 markets :\n",
    "* Advertising budgets for TV, radio, and newspaper (in thousands of dollars)\n",
    "* The sales (in thousands of units)\n",
    "\n",
    "We wish to understand association between advertising and sales to control advertising expenditure in each of the three media. \n",
    "\n",
    "**Input variables** ($X$) :\n",
    "* $X_1$ : TV budget\n",
    "* $X_2$ : Radio budget\n",
    "* $X_3$ : newspaper budget\n",
    "\n",
    "**Output variable** :\n",
    "* $Y$ : Sales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relationship between $Y$ and $X$ :\n",
    "\n",
    "$$\n",
    "Y = f(X) + \\epsilon\n",
    "$$\n",
    "\n",
    "where $f$ is an unkdown function and $\\epsilon$ a random error term independent of $X$ and which has mean zero (otherwise easy to compensate by modifying $f$). This error cannot be reduced to zero. For example, it may depend on unmeasured variables that are useful for predicting the value of $Y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "advertising.plot(kind='scatter', color='Blue', x='TV', y='sales')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ordinary Least Squares\n",
    "X = advertising['TV']\n",
    "Y = advertising['sales']\n",
    "regression = np.polyfit(X, Y, deg=1)\n",
    "\n",
    "advertising.plot(kind='scatter', color='Blue', x='TV', y='sales')\n",
    "\n",
    "plt.plot(X, regression[0]*X + regression[1], 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression\n",
    "\n",
    "Given a collection of n points, find the line which best approximates or fits the points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a random noise\n",
    "x1 = np.random.normal(size=200)\n",
    "x = np.linspace(x1.min()-1, x1.max()+1, 100)\n",
    "y = 3*(np.random.normal(0, 1, 100)+x)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x, y , color='red')\n",
    "\n",
    "#Find the regression line\n",
    "regression = np.polyfit(x, y, 1)\n",
    "print(regression)\n",
    "longerX = np.append(x, [5,-5])\n",
    "ax.plot(longerX, regression[0]*longerX + regression[1], color='black', linewidth='1.5')\n",
    "ax.set_xlim(-4, 4.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "f(x) = mx + p\n",
    "$$\n",
    "\n",
    "The residual error is defined:\n",
    "\n",
    "$$\n",
    "r_i = y_i - f(x_i)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = np.linspace(0, 10, 100)\n",
    "y = 2*x+3\n",
    "#distance the dashed line is into the circle\n",
    "s = 0.4\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, y)\n",
    "ax.plot([1, 1, 2, 3, 3, 4, 4, 5, 6, 7],[7, 3, 12, 5, 11, 15, 10, 15, 12, 19], 'yo', markersize=7)\n",
    "ax.plot([1, 1], [7-s, 5], 'b-', [1, 1], [3+s, 5], 'b-', \\\n",
    "[2, 2], [12-s, 7], 'b-', [3, 3], [5+s, 9], 'b-', \\\n",
    "[3, 3], [11-s, 9], 'b-', [4,4], [15-s, 11], 'b-', \\\n",
    "[4,4], [10+s, 11], 'b-', [5, 5], [15-s, 13], 'b-',\\\n",
    "[6, 6], [12+s+0.1, 15], 'b-', [7, 7], [19-s, 17], 'b-', linestyle='dashed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consider a set of $n$ points $x_i = (x_{i1}, x_{i2}, \\ldots, x_{im})$, where\n",
    "$(x_{i1}, x_{i2}, \\ldots, x_{i(m-1)})$ is the feature vector and $x_{im}$ is\n",
    "the **target variable**.\n",
    "\n",
    "We use the **least squares regression** to find the optimal fit :\n",
    "\n",
    "$$\n",
    "\\sum_{i=1}^n (y_i - f(x_i))^2, \\text{where}\\ f(x) = w_0 + \\sum_{j=1}^{m-1}w_jx_j\n",
    "$$\n",
    "\n",
    "The vector of residual values :\n",
    "\n",
    "$$\n",
    "(b - A \\cdot w),\n",
    "$$\n",
    "\n",
    "where b, A, and w are defined as follows:\n",
    "\n",
    "$$\n",
    "b = \\left[\n",
    "\\begin{array}{c}\n",
    "  x_{1m}\\\\\n",
    "  x_{2m}\\\\\n",
    "  \\vdots \\\\\n",
    "  x_{im}\\\\\n",
    "  \\vdots \\\\\n",
    "  x_{nm}\n",
    "\\end{array}\n",
    "\\right], A = \\left[\n",
    "\\begin{array}{ccccccc}\n",
    "  1 & x_{11} & x_{12} & \\ldots & x_{1j} & \\ldots & x_{1(m-1)} \\\\\n",
    "  1 & x_{21} & x_{22} & \\ldots & x_{2j} & \\ldots & x_{2(m-1)} \\\\\n",
    "  \\vdots & \\vdots & \\vdots & \\ddots & \\vdots & \\ddots & \\vdots \\\\\n",
    "  1 & x_{i1} & x_{i2} & \\ldots & x_{ij} & \\ldots & x_{i(m-1)} \\\\\n",
    "  \\vdots & \\vdots & \\vdots & \\ddots & \\vdots & \\ddots & \\vdots \\\\\n",
    "  1 & x_{n1} & x_{n2} & \\ldots & x_{nj} & \\ldots & x_{n(m-1)}\n",
    "\\end{array}\n",
    "\\right], w = \\left[\n",
    "\\begin{array}{c}\n",
    "  w_0\\\\\n",
    "  w_1\\\\\n",
    "  \\vdots \\\\\n",
    "  w_j \\\\\n",
    "  \\vdots \\\\\n",
    "  w_{(m-1)}\n",
    "\\end{array}\n",
    "\\right].\n",
    "$$\n",
    "\n",
    "The vector $w$ that leads to the best fitting line is given by :\n",
    "\n",
    "$$\n",
    "w = (A^T A)^{-1}A^T b\n",
    "$$\n",
    "\n",
    "The right-hand side of this equation comprises the following components:\n",
    "\n",
    "* $A^T A$ : the *covariance matrix* on the features of the data matrix\n",
    "* $A^T b$ : this dot product between features and the target values measure how correlated are each feature with the targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax2, ax1) = plt.subplots(ncols=2, figsize=(12,4.5))\n",
    "\n",
    "# The right graph without an outlier.\n",
    "# Create a random 15 points\n",
    "np.random.seed(7)\n",
    "x1 = np.random.normal(size=10)\n",
    "x = np.linspace(x1.min()-1, x1.max()+1, 15) \n",
    "y = 3*(np.random.normal(0, 1, 15)+x)\n",
    "ax1.scatter(x, y, color='red')\n",
    "\n",
    "# Find the regression line\n",
    "regression = np.polyfit(x, y, deg=1)\n",
    "longerX = np.append(x, [5,-5]) # this makes the regression line longer\n",
    "ax1.plot(longerX, regression[0]*longerX + regression[1], color='black', linewidth='1.5')\n",
    "ax1.set_xlim(-3.5, 4.5)\n",
    "ax1.set_ylim(-15, 20)\n",
    "# The correlation coefficient value r.\n",
    "r1 = stats.pearsonr(x, y)\n",
    "ax1.set_title('Correlation coefficient = {:.2}'.format(r1[0]))\n",
    "\n",
    "# The left graph with an outlier\n",
    "# plot the 15 points with an outlier.\n",
    "x1 = np.append(x, [4])\n",
    "y1 = np.append(y, [-10])\n",
    "ax2.scatter(x1, y1, color='red')\n",
    "\n",
    "# Find the regression line\n",
    "regression = np.polyfit(x1, y1, deg=1)\n",
    "longerX = np.append(x1, [5,-5]) # this makes the regression line longer\n",
    "ax2.plot(longerX, regression[0]*longerX + regression[1], color='black', linewidth='1.5')\n",
    "ax2.set_xlim(-3.5, 4.5)\n",
    "ax2.set_ylim(-15, 20)\n",
    "# The correlation coefficient value r.\n",
    "r2 = stats.pearsonr(x1, y1)\n",
    "ax2.set_title('Correlation coefficient = {:.2}'.format(r2[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Least square regression are sensitive to outlier, because they have a large impact on the following objective function :\n",
    "\n",
    "$$\n",
    "\\sum_{i=1}^n (y_i - f(x_i))^2\n",
    "$$\n",
    "\n",
    "For example, compare the impact of a point at distance 10 and a second point at distance 1 from the line.\n",
    "\n",
    "A simple solution for dealing with such points, is to first compute a linear regression on the complete data set. Then, compare residual values $r_i = (y_i - f(x_i))^2$ to determine which points are outliers in the dataset. Finaly, compute a new linear regression without these points. However, are we sure these points represent errors ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting Non-Linear Functions\n",
    "\n",
    "How to fit a quadratic model ? \n",
    "\n",
    "$$\n",
    "y = w_0 + w_1 x + w_2 x^2\n",
    "$$\n",
    "\n",
    "Add a new column to the data matrix equal to $x^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,4.5))\n",
    "\n",
    "n = 20\n",
    "x = np.linspace(0, n, n) \n",
    "y = np.random.normal(0, 10, n) + 0.5 * x**2\n",
    "ax.scatter(x, y, color='red')\n",
    "\n",
    "# Fit the model\n",
    "A = np.vstack((np.ones(len(x)), x, x**2)).T\n",
    "w = np.linalg.lstsq(A, y)[0]\n",
    "\n",
    "# Predict\n",
    "x = np.linspace(-5, n+5, 10*n) \n",
    "A = np.vstack((np.ones(len(x)), x, x**2)).T\n",
    "ax.plot(x, np.dot(A, w), 'b')\n",
    "ax.set_xlim(-5, n+5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling\n",
    "\n",
    "Let us consider the following prediction problem :\n",
    "\n",
    "* $y$ : Gross national product (in dollars)\n",
    "* $x_1$ : Population size\n",
    "* $x_2$ : Literacy rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Country Name', '2016']\n",
    "gdp = pandas.read_csv('../datasets/API_NY.GDP.MKTP.CD_DS2_en_csv_v2.csv',\n",
    "                      index_col=0, skiprows=4, usecols=cols)\n",
    "gdp.rename(columns={'2016' : 'GDP'}, inplace=True);\n",
    "gdp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "literacy = pandas.read_csv('../datasets/API_SE.ADT.LITR.ZS_DS2_en_csv_v2.csv',\n",
    "                           index_col=0, skiprows=4, usecols=cols)\n",
    "literacy.rename(columns={'2016' : 'Literacy'}, inplace=True);\n",
    "literacy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population = pandas.read_csv('../datasets/API_SP.POP.TOTL_DS2_en_csv_v2.csv',\n",
    "                               index_col=0, skiprows=4, usecols=cols)\n",
    "population.rename(columns={'2016' : 'Population'}, inplace=True);\n",
    "population.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pandas.concat([population, gdp, literacy], axis=1)\n",
    "df.dropna(inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "A = np.vstack((np.ones(df.shape[0]), df['Population'], df['Literacy'])).T\n",
    "w = np.linalg.lstsq(A, df['GDP'])[0]\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Issues in such models :\n",
    "    \n",
    "* Unreadable coefficients\n",
    "* Numerical imprecision\n",
    "* Inapproprite formulations\n",
    "\n",
    "Scaling operations are used to address these problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlated Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression as a Parameter Fitting Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "* [An Introduction to Statistical Learning with Applications in R](http://www-bcf.usc.edu/~gareth/ISL/) by Gareth James, Daniela Witten, Trevor Hastie and Robert Tibshirani\n",
    "* **The Data Science Design Manual**, by Steven Skiena, 2017, Springer\n",
    "* Python notebooks available at [http://data-manual.com/data](http://data-manual.com/data)\n",
    "* Lectures slides available at [http://www3.cs.stonybrook.edu/~skiena/data-manual/lectures/](http://www3.cs.stonybrook.edu/~skiena/data-manual/lectures/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
